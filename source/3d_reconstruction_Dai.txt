一、三维视觉
    1.基于二维图像的三维感知
        动态场景智能三维环境感知，实现具有稠密/半稠密三维点云表示：速度+位置+位姿
        非刚体物体的三维重建技术

    2.事件相机去模糊——仿生成像
        人眼对于视觉信息是事件的获取——事件相机：低延迟、高帧率、高动态范围
        从模糊帧重建高帧率视频——监督学习、无监督学习——事件相机去模糊
        单目深度估计：
            RGBD：深度估计+光流估计+图像分割 -> f(I) = Depth
            解决办法：连续帧视频、深度相机、图生世界的技术迁移
        双目立体匹配(Stereo Matching):
            Test-Time Computation 
            双目相机图像对：通过包含足够多的图像可以根据自身具备的深度信息，实现自监督训练

    3.三维视觉重建、理解、生成
        Reconstruction, Recognition, Reorganization
        correspondence: 相似; 一致; 相符 
        相机：成像原理——小孔成像, 增加镜头但是适用于某个聚焦距离
        (1).单视角三维重建：
            知识推理+数据驱动方法->3D重建
        (2).图像平面测量：
            基于已知的距离信息进行推导

    4.直接线性标定
        张正友: 3D->2D->1D->无标定

v
二、三维点云
    1. 对称函数的应用
        PointNet 使用了一个称为“对称函数”的操作来聚合点特征。在 PointNet 中，
        这个对称函数通常是最大池化（Max Pooling）。最大池化操作具有排列不变性，
        这意味着无论输入序列如何排序，最大值总是相同的。通过这种方式，PointNet
        能够确保对于任意给定点集的变换（如重新排序），网络的最终输出保持一致。
        具体来说，在 PointNet 中，首先每个点通过一个多层感知机（MLP）转换为更
        高维度的特征向量。然后，所有这些特征向量被送入一个全局的最大池化层，以
        产生一个全局特征描述符。这个过程可以用以下公式表示：
    2. 共享参数的多层感知机 (MLP)
        在 PointNet 中，每个点都通过共享权重的多层感知机进行处理。这意味着
        每个点都被独立地映射到一个新的特征空间，而不依赖于其他点的位置或顺序。
        这种设计保证了即使点的顺序发生变化，每个点的特征表示也不会改变。
    3. 局部与全局信息的结合
        除了提取全局特征外，PointNet 还可以通过将全局特征与每个点的
        局部特征相结合来增强模型的表现力。这通常通过连接（concatenation）
        操作实现：每个点的原始特征和全局特征被拼接在一起，然后再次通过 
        MLP 来生成最终的逐点特征。
    4.总结
        对称函数：使用最大池化作为对称函数来聚合点特征，从而确保网络输出不受点顺序的影响。
        共享参数的MLP：通过共享权重的多层感知机处理每个点，使得每个点的特征表示独立于其它点的顺序。
        局部与全局信息结合：通过将全局特征与局部特征结合，进一步提升模型性能。
    排列不变性：最大函数Max; 
    旋转不变性：乘以一个旋转矩, 正则化优化L_reg = ||I - R^T R||^2目标函数;
    分割的任务：将MLP的输出部分concat( nx64, nx1024 ), 再使用shared mlp layer做输出nx128;


    
            